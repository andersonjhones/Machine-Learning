{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kfold_usando_modelos_da_sklearn",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3SRsQ/5Bzav7pysn68yux",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andersonjhones/Machine-Learning/blob/main/kfold_usando_modelos_da_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pode-se encontrar nesse notebook python um exemplo de como aplicar validação cruzada ao seu conjunto de dados, com intuito de utilizar todos os dados como treino e teste e coletar o resultado da performance média dos resultados dos K folds aplicados. Por exemplo, você pode aplicar 10 folds, ou seja, o conjunto de dados vai ter em cada iteração 10 divisões e uma parte das 10 vai ser a parte de teste, em cada itereção os conjuntos de treino e teste mudam, garantindo, assim, que todo o conjunto de dados foi utilizado tanto para treino como para teste. Pode-se então tirar a média dos 10 resultados e ter um resultado médio de performance. "
      ],
      "metadata": {
        "id": "CxRQvc9YYldx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import cross_val_score # Função para validação cruzada.\n",
        "from sklearn.model_selection import KFold # KFold.\n",
        "from sklearn.linear_model import LinearRegression # Classe para regressão linear.\n",
        "\n",
        "df = pd.read_csv(\"/content/Admission_Predict.csv\") #Conjunto de dados\n",
        "\n",
        "df.drop('Serial No.', axis = 1, inplace = True) # Exclusão da coluna de identificação, pois não é necessária para as previsões.\n",
        "# Divisão dos preditores e da variável objetivo (variável a ser predita)\n",
        "x = df.drop('Chance of Admit ', axis = 1) # Excluindo a variável objetivo do conjunto de preditores\n",
        "y = df['Chance of Admit '] # Variável Target (Objetivo)\n",
        "\n",
        "modelo  = LinearRegression()  #Instãncia do modelo de regressão linear\n",
        "kfold  = KFold(n_splits=10, shuffle=True) # 10 folds e embaralhamento dos dados com shuffle.\n",
        "resultado = cross_val_score(modelo, x, y, cv = kfold) #Resultados\n",
        "\n",
        "print(\"K-Fold (R^2) Scores: {0}\".format(resultado)) # Mostrando os sores dos 10 folds \n",
        "print(\"Mean R^2 for Cross-Validation K-Fold: {0}\".format(resultado.mean())) # A média do R2 score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC-mNNxjRH8D",
        "outputId": "27bd8907-bf6a-4d62-b852-309b0fa5eec4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Fold (R^2) Scores: [0.77632619 0.74747534 0.8145954  0.80409991 0.85680798 0.80746262\n",
            " 0.67939853 0.84478543 0.75367176 0.83604988]\n",
            "Mean R^2 for Cross-Validation K-Fold: 0.7920673038672201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQmyLzmlMo2M",
        "outputId": "30e91e2e-4699-4a99-91bb-4da9e3fa775c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média da regressão linear (R^2): 0.7826836406964535\n",
            "Média ElasticNet (R^2): 0.5416940919827071\n",
            "Média Ridge  (R^2): 0.7945599702413165\n",
            "Média Lasso (R^2): 0.2572682690888821\n",
            "O melhor modelo é: Ridge with value: 0.7945599702413165\n"
          ]
        }
      ],
      "source": [
        "def KFold_Models(x_, y_): #Definindo a função com os modelos utilizados no exemplo\n",
        "  # Modelos lineares.\n",
        "  from sklearn.linear_model import LinearRegression\n",
        "  from sklearn.linear_model import ElasticNet\n",
        "  from sklearn.linear_model import Ridge\n",
        "  from sklearn.linear_model import Lasso\n",
        "\n",
        "  # Importando cross validation score e kfold do sklearn.\n",
        "  from sklearn.model_selection import cross_val_score\n",
        "  from sklearn.model_selection import KFold\n",
        "\n",
        "  # KFold.\n",
        "  kfold  = KFold(n_splits=10, shuffle=True) # shu10 folds e embaralhamento dos dados com shuffle.\n",
        "\n",
        "  # Preditores e variável target (y) recebendo os objetos da função KFold_Models\n",
        "  x = x_\n",
        "  y = y_\n",
        "\n",
        "  # Instâncias dos modelos.\n",
        "  linearRegression = LinearRegression()\n",
        "  elasticNet       = ElasticNet()\n",
        "  ridge            = Ridge()\n",
        "  lasso            = Lasso()\n",
        "\n",
        "  # Aplicação do kfold nos modelos.\n",
        "  linearRegression_result = cross_val_score(linearRegression, x, y, cv = kfold)\n",
        "  elasticNet_result       = cross_val_score(elasticNet, x, y, cv = kfold)\n",
        "  ridge_result            = cross_val_score(ridge, x, y, cv = kfold)\n",
        "  lasso_result            = cross_val_score(lasso, x, y, cv = kfold)\n",
        "\n",
        "  # Dicionário armazenando os modelos.\n",
        "  dic_models = {\n",
        "    \"LinearRegression\": linearRegression_result.mean(),\n",
        "    \"ElasticNet\": elasticNet_result.mean(),\n",
        "    \"Ridge\": ridge_result.mean(),\n",
        "    \"Lasso\": lasso_result.mean()\n",
        "  }\n",
        "  # Seleção do melhor modelo.\n",
        "  bestModel = max(dic_models, key=dic_models.get)\n",
        "\n",
        "  print(\"Média da regressão linear (R^2): {0}\\nMédia ElasticNet (R^2): {1}\\nMédia Ridge  (R^2): {2}\\nMédia Lasso (R^2): {3}\".format(linearRegression_result.mean(), elasticNet_result.mean(), ridge_result.mean(), lasso_result.mean()))\n",
        "  print(\"O melhor modelo é: {0} with value: {1}\".format(bestModel, dic_models[bestModel]))\n",
        "\n",
        "\n",
        "if __name__ =='__main__':\n",
        "  import pandas as pd\n",
        "\n",
        "  df = pd.read_csv(\"/content/Admission_Predict.csv\")\n",
        "  df.drop('Serial No.', axis = 1, inplace = True)\n",
        "\n",
        "  x = df.drop('Chance of Admit ', axis = 1)\n",
        "  y = df['Chance of Admit ']\n",
        "\n",
        "  KFold_Models(x, y)"
      ]
    }
  ]
}